{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "\n",
    "The purpose of this code is to calibrate our camera using the 20 chessboard images provided.\n",
    "\n",
    "A chessboard is used for camera calibration since its regular patterns of high contrast make it easy to detect automatically. So, if we use our camera to take multiple pictures of chessboard agaisnt a flat surface, then we will be able to detect any distortion by looking at the difference between the appartent size and shape of the squares of the chessboard pattern.\n",
    "\n",
    "We will start by importing all relevant libraries such as opencv, numpy required.\n",
    "\n",
    "The Project\n",
    "---\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "import natsort\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Corners\n",
    "\n",
    "In this exercise, you'll use the OpenCV functions **findChessboardCorners()** and **drawChessboardCorners()** to automatically find and draw corners in an image of a chessboard pattern.\n",
    "\n",
    "To learn more about both of those functions, you can have a look at the OpenCV documentation here: [**cv2.findChessboardCorners()**](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.findChessboardCorners) and [**cv2.drawChessboardCorners()**](https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#cv2.drawChessboardCorners).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibrate Camera Function\n",
    "\n",
    "Camera calibration, given object points, image points, and the shape of the grayscale image:\n",
    "\n",
    "#### ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "Undistorting a test image:\n",
    "\n",
    "#### dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "\n",
    "### Correcting for distortion\n",
    "\n",
    "There are two main steps to this process: use chessboard images to obtain image points and object points, and then use the OpenCV functions cv2.calibrateCamera() and cv2.undistort() to compute the calibration and undistortion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_camera(nx, ny):\n",
    "    # function to calibrate the camera over different chessboard images and input the x and y corners\n",
    "\n",
    "    # get the list of images\n",
    "    images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "    # sorting the images based on ids\n",
    "    images = natsort.natsorted(images)\n",
    "    # images = glob.glob('test_images/test*.jpg')\n",
    "\n",
    "    # creating arrays to store object and image points from all the images\n",
    "    objpoints = []      # 3D object points in real space\n",
    "    imgpoints = []      # 2D points in image space\n",
    "\n",
    "    # prepare object points\n",
    "    objp = np.zeros((ny*nx, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)    # x, y cor-ordinates\n",
    "\n",
    "    # iterate through the images\n",
    "    for fname in images:\n",
    "\n",
    "        # read file\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # grab the filenames and extensions for saving result files later\n",
    "        filename_w_ext = os.path.basename(fname)\n",
    "        filename, file_extension = os.path.splitext(filename_w_ext)\n",
    "\n",
    "        # convert image to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        # print(ret)\n",
    "\n",
    "        # If found, we will get image coordinates\n",
    "        if (ret == True):\n",
    "            # add the corners and objectpoints to our lists\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "\n",
    "            # draw and display the corners\n",
    "            img_corners = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "            # cv2.imshow('img',img_corners)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            # save the drawn chessboard corners\n",
    "            # mpimg.imsave(('output_images/chessboard_corners/'+filename+'-corners'+file_extension), img_corners)\n",
    "            # cv2.imwrite(('output_images/chessboard_corners/'+'corners-'+filename+file_extension), img_corners)\n",
    "\n",
    "            # calculate and save undistorted images\n",
    "            # ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img.shape[1::-1], None, None)\n",
    "            # undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "            # cv2.imwrite(('output_images/undistorted_chessboard_corners/'+'undistorted-'+filename+file_extension), undist)\n",
    "        \n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    # sample one image for undistortion demo\n",
    "    \n",
    "    img = cv2.imread('camera_cal/calibration3.jpg')\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # camera calibration after giving object points and image points\n",
    "\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    cv2.imwrite('output_images/test_undist.jpg',dst)\n",
    "    \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    pickle.dump( dist_pickle, open( \"pickle/wide_dist_pickle.p\", \"wb\" ) )\n",
    "    \n",
    "    # Visualize undistortion\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,9))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted Image', fontsize=20)\n",
    "    plt.show()\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    \n",
    "    return mtx, dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform Function\n",
    "\n",
    "A perspective transform maps the points in a given image to different, desired, image points with a new perspective. The perspective transform you’ll be most interested in is a bird’s-eye view transform that let’s us view a lane from above; this will be useful for calculating the lane curvature later on. Aside from creating a bird’s eye view representation of an image, a perspective transform can also be used for all kinds of different view points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unwarp_corners(mtx,dist):\n",
    "\n",
    "    img = cv2.imread('camera_cal/calibration3.jpg')\n",
    "\n",
    "    nx = 9\n",
    "    ny = 6\n",
    "\n",
    "    # Use the OpenCV undistort() function to remove distortion\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    # Convert undistorted image to grayscale\n",
    "    gray = cv2.cvtColor(undist, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Search for corners in the grayscaled image\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    # print(ret)\n",
    "    \n",
    "    if ret == True:\n",
    "        # If we found corners, draw them! (just for fun)\n",
    "        cv2.drawChessboardCorners(undist, (nx, ny), corners, ret)\n",
    "        # Choose offset from image corners to plot detected corners\n",
    "        # This should be chosen to present the result at the proper aspect ratio\n",
    "        # My choice of 100 pixels is not exact, but close enough for our purpose here\n",
    "\n",
    "        # Specify offset for dst points\n",
    "        offset = 100\n",
    "\n",
    "        # Grab the image shape\n",
    "        img_size = (gray.shape[1], gray.shape[0])\n",
    "\n",
    "        # For source points, let us grab the detected outer four corners\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        # For destination points, I'm arbitrarily choosing some points to be\n",
    "        # a nice fit for displaying our warped result \n",
    "        # again, not exact, but close enough for our purposes\n",
    "        dst = np.float32([[offset, offset], [img_size[0]-offset, offset],\\\n",
    "                          [img_size[0]-offset, img_size[1]-offset],\\\n",
    "                          [offset, img_size[1]-offset]])\n",
    "        # Given src and dst points, calculate the perspective transform matrix\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        # Warp the image using OpenCV warpPerspective()\n",
    "        warped = cv2.warpPerspective(undist, M, img_size)\n",
    "        \n",
    "    # vizualize the data\n",
    "        \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=20)\n",
    "    ax2.imshow(warped)\n",
    "    ax2.set_title('Undistorted and Warped Image', fontsize=20)\n",
    "    plt.show()\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "        \n",
    "    return M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Calibrate_Camera() and Unwarp_Corners() Functions\n",
    "\n",
    "Now, we will call **Calibrate Camera** and **Unwarp Corners** functions.\n",
    "\n",
    "(Note: In the camera calibrate function, I have included code that iterates through all the 20 calibration images to draw detected chessboard corners and save the output images. After running once and the images have been saved, the lines **cv2.imwrite(('output_images/chessboard_corners/'+filename+'-corners'+file_extension), img_corners)** and **cv2.imwrite(('output_images/undistorted_chessboard_corners/'+filename+'-undistorted'+file_extension), undist)** can be commented out.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function calls to calibrate camera and get the perspective matrix\n",
    "mtx, dist = calibrate_camera(9,6)\n",
    "perspective_M = unwarp_corners(mtx, dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding Functions\n",
    "\n",
    "In this section, I have written functions for calculating parameters such as Sobel Intensity Gradients, Gradient magnitude, gradient direction, hue, lightness, saturation and applying threshold values to idetify lanelines in images. Each of these functions will extract a binary image with the applied threshold values.\n",
    "\n",
    "The idea behind writing different functions is that there is little extra effort involved and it is possible to use multiple combinations of these filters to achieve the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding functions\n",
    "# since we have evaludated earlier that HLS gives good image filtering results\n",
    "\n",
    "def hue_select(img, thresh = (0,255)):\n",
    "\n",
    "    # 1. convert to hls colorspace\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    \n",
    "    # 2. apply threshold to s channel\n",
    "    h_channel = hls[:,:,0]\n",
    "\n",
    "    # 3. create empty array to store the binary output and apply threshold\n",
    "    binary_image = np.zeros_like(h_channel)\n",
    "    binary_image[(h_channel > thresh[0]) & (h_channel <= thresh[1])] = 1\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "def lightness_select(img, thresh = (120,255)):\n",
    "    \n",
    "    # 1. Convert to hls colorspace\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    # 2. Apply threshold to s channel\n",
    "    l_channel = hls[:,:,0]\n",
    "\n",
    "    # 3. Create empty array to store the binary output and apply threshold\n",
    "    binary_output = np.zeros_like(l_channel)\n",
    "    binary_output[(l_channel > thresh[0]) & (l_channel <= thresh[1])] = 1\n",
    "\n",
    "    return binary_output\n",
    "\n",
    "def saturation_select(img, thresh = (100,255)):\n",
    "\n",
    "    # 1. convert to hls colorspace\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "\n",
    "    # 2. apply threshold to s channel\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # 3. create empty array to store the binary output and apply threshold\n",
    "    binary_image = np.zeros_like(s_channel)\n",
    "    binary_image[(s_channel > thresh[0]) & (s_channel <= thresh[1])] = 1\n",
    "\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "\n",
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel depending on x or y direction and getting the absolute value\n",
    "    if (orient == 'x'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel))\n",
    "    if (orient == 'y'):\n",
    "        abs_sobel = np.absolute(cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel))\n",
    "\n",
    "    # 2. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "\n",
    "    # 3. Create mask of '1's where the sobel magnitude is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def mag_sobel(img, sobel_kernel=3, mag_thresh = (0,255)):\n",
    "\n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "\n",
    "    # 2. Magnitude of Sobel\n",
    "    mag_sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "\n",
    "    # 3. Scaling to 8-bit and converting to np.uint8\n",
    "    scaled_sobel = np.uint8(255*mag_sobel/np.max(mag_sobel))\n",
    "\n",
    "    # 4. Create mask of '1's where the scaled gradient magnitude is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output\n",
    "\n",
    "\n",
    "# Choose a Sobel kernel size\n",
    "\n",
    "def dir_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    \n",
    "    # 1. Applying the Sobel (taking the derivative)\n",
    "    sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize = sobel_kernel)\n",
    "    sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize = sobel_kernel)\n",
    "    \n",
    "    # 2. Take absolute magnitude\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "    \n",
    "    # 3. Calculate direction using arctangent\n",
    "    sobel_orient = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    # 4. Create mask of '1's where the orientation is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(sobel_orient)\n",
    "    binary_output[(sobel_orient > thresh[0]) & (sobel_orient <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Thresholding Function\n",
    "\n",
    "Using this function, we combine different threshold values together in a binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined Threshold Function\n",
    "def combined_threshold(img):\n",
    "\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    s_channel = hls[:,:,2]\n",
    "    l_select = hls[:,:,1]\n",
    "\n",
    "    # convert image to grayscale\n",
    "    gray = cv2.cvtColor(hls, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # applying thresholding and storing different filtered images\n",
    "\n",
    "    h_binary = hue_select(img, thresh = (0, 255))\n",
    "    l_binary = lightness_select(img, thresh = (120, 255))\n",
    "    s_binary = saturation_select(img, thresh = (100, 255))\n",
    "    \n",
    "    ksize = 9\n",
    "    gradex = abs_sobel_thresh(s_channel, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    # grady = abs_sobel_thresh(gray, orient='y', sobel_kernel=ksize, thresh=(50, 255))\n",
    "\n",
    "    mag_binary = mag_sobel(gray, sobel_kernel=ksize, mag_thresh=(50, 255))\n",
    "    dir_binary = dir_threshold(gray, sobel_kernel=ksize, thresh=(0.7,1.3))\n",
    "\n",
    "    # creating an empty binary image\n",
    "    combined_binary = np.zeros_like(img)\n",
    "    combined_binary[((gradex == 1) | (s_binary == 1)) & ((l_binary == 1) & (h_binary == 1))] = 1\n",
    "\n",
    "    # isolate region of interest\n",
    "    height, width = gray.shape\n",
    "\n",
    "    mask = np.zeros_like(combined_binary)\n",
    "    region = np.array([[0, height-1], [width/2, int(height/2)], [width-1, height-1]], dtype=np.int32)\n",
    "    cv2.fillPoly(mask, [region], 1)\n",
    "\n",
    "    combined_binary = cv2.bitwise_and(combined_binary, mask)\n",
    "\n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perspective Transform\n",
    "\n",
    "After applying the thresholds, isolating the regions of interest and getting our binary image with identified lanelines, we apply the perspective transform to the image.\n",
    "We do this using **cv2.getPerspectiveTransform(source, dst)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perspective_transform(img):\n",
    "    \n",
    "    height, width = img.shape\n",
    "    \n",
    "    # select the four points on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fname = cv2.imread('test_images/straight_lines1.jpg')\n",
    "result = combined_threshold(fname)\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
